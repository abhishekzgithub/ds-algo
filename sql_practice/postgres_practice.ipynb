{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b261f22-01e2-43b9-a33f-c283796bed10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SparkJob at 0x1a75fb4ccd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"SPARK_HOME\"]=r\"C:\\Users\\abhi3\\Documents\\work\\ds-algo\\pyspark_practice\\spark-3.5.3-bin-hadoop3\\spark-3.5.3-bin-hadoop3\"\n",
    "os.environ[\"JAVA_HOME\"]=r'C:\\Program Files\\Java\\jre1.8.0_431'\n",
    "os.environ[\"HADOOP_HOME\"]=r\"C:\\Users\\abhi3\\Documents\\work\\ds-algo\\pyspark_practice\\spark-3.5.3-bin-hadoop3\\spark-3.5.3-bin-hadoop3\\hadoop\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"jupyter\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime, date\n",
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "class SparkJob:\n",
    "    JAR_LOCATION=r\"C:\\Users\\abhi3\\Documents\\work\\ds-algo\\sql_practice\\postgresql-42.7.2.jar\"\n",
    "    JDBC_URL = \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "    PROPERTIES = {\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"7fd2c637bef349a587ed0b6456d04f14\",\n",
    "            \"driver\": \"org.postgresql.Driver\"\n",
    "        }\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.spark = (SparkSession\n",
    "                 .builder\n",
    "                 .appName(\"MyApp\")\n",
    "                 .config(\"spark.driver.extraClassPath\", self.JAR_LOCATION)\n",
    "                 .getOrCreate())\n",
    "    \n",
    "    def read_from_db(self,tablename):\n",
    "        \"\"\"\n",
    "        f\"public.\\\"{tablename}\\\"\"\n",
    "        \"\"\"\n",
    "        df = self.spark.read.jdbc(self.JDBC_URL, tablename, properties=self.PROPERTIES)\n",
    "        return df\n",
    "    def read_csv(self,filename):\n",
    "        return self.spark.read.csv(filename)\n",
    "\n",
    "    def read_from_text(self,text_path,columns):\n",
    "        file_read=self.spark.read.text(text_path)\n",
    "        index_rdd=file_read.rdd.map(lambda x: x.value.split()) #to split the elements\n",
    "        index_rdd=index_rdd.filter(lambda x:x) #to remove the null\n",
    "        index_rdd=index_rdd.toDF(columns)\n",
    "        return index_rdd\n",
    "    def write_to_db(self, dataframe,tablename):\n",
    "        return dataframe.write.jdbc(url=self.JDBC_URL, table=tablename, mode=\"overwrite\", properties=self.PROPERTIES)\n",
    "\n",
    "\n",
    "spark=SparkJob()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e90bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandasql import sqldf\n",
    "from io import StringIO\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "\n",
    "class PostgresOps:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.engine = create_engine('postgresql://postgres:7fd2c637bef349a587ed0b6456d04f14@localhost:5432/postgres')\n",
    "        self.current_dir= pathlib.Path(os.path.abspath(''))\n",
    "    \n",
    "    def get_excel_path(self, filename):\n",
    "        return str(list(self.current_dir.glob(f\"{filename}\"))[0])\n",
    "    \n",
    "    def read_from_db(self,table):\n",
    "        return pd.read_sql_table(table,self.engine)\n",
    "    \n",
    "    def write_to_db(self,df,tablename):\n",
    "        engine=self.engine\n",
    "        return df.to_sql(tablename, engine,index=False,if_exists='replace',schema=\"public\")\n",
    "    \n",
    "    def read_from_excel(self,sheetname,filepath=None):\n",
    "        filepath=filepath or self.filepath\n",
    "        return pd.read_excel(filepath,sheet_name=sheetname)\n",
    "    \n",
    "    def read_from_csv(self,filepath=None,sep=\"\\t\"):\n",
    "        filepath=filepath or self.csv_path\n",
    "        return pd.read_csv(filepath,sep=\"\\t\")\n",
    "\n",
    "    \n",
    "    def convert_datetime(self,df,date_column):\n",
    "        df[date_column]=pd.to_datetime(df[date_column])\n",
    "        return df\n",
    "\n",
    "    def read_csv_var(self,csv_string,sep=\"\\t\",header=0):\n",
    "        csvStringIO = StringIO(csv_string)\n",
    "        df = pd.read_csv(csvStringIO, sep=sep, header=header)\n",
    "        return df\n",
    "        \n",
    "\n",
    "p=PostgresOps()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06e1c7d-28ea-4ad7-b933-3b573cb05a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\"headers\":{\"Products\":[\"product_id\",\"new_price\",\"change_date\"]},\"rows\":{\"Products\":[[1,20,\"2019-08-14\"],[2,50,\"2019-08-14\"],[1,30,\"2019-08-15\"],[1,35,\"2019-08-16\"],[2,65,\"2019-08-17\"],[3,20,\"2019-08-18\"]]}}\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0932b213-11d6-4d0f-a483-ed09d09005a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheetname=\"test\"\n",
    "sheetname=\"Works\"\n",
    "sheetname=\"departments\"\n",
    "sheetname=\"Employees\"\n",
    "sheetname=\"Employee\"\n",
    "sheetname=\"user_content\"\n",
    "sheetname=\"Logs\"\n",
    "filepath=p.get_excel_path(\"sql_dataframe.xlsx\")\n",
    "print(filepath)\n",
    "df=p.read_from_excel(sheetname,filepath)\n",
    "print(df.head())\n",
    "df.to_sql(sheetname, p.engine,index=False,if_exists='replace')\n",
    "df1=pd.read_sql_table(sheetname, p.engine, schema=None, index_col=None, \n",
    "                     coerce_float=True, parse_dates=None, columns=None, chunksize=None)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6afb0203-2f74-4764-b660-48e960f7690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+------+\n",
      "|customer_id|   name|visited_on|amount|\n",
      "+-----------+-------+----------+------+\n",
      "|          1|   Jhon|2019-01-01|   100|\n",
      "|          2| Daniel|2019-01-02|   110|\n",
      "|          3|   Jade|2019-01-03|   120|\n",
      "|          4| Khaled|2019-01-04|   130|\n",
      "|          5|Winston|2019-01-05|   110|\n",
      "|          6|  Elvis|2019-01-06|   140|\n",
      "|          7|   Anna|2019-01-07|   150|\n",
      "|          8|  Maria|2019-01-08|    80|\n",
      "|          9|   Jaze|2019-01-09|   110|\n",
      "|          1|   Jhon|2019-01-10|   130|\n",
      "|          3|   Jade|2019-01-10|   150|\n",
      "+-----------+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_path=r\"C:\\Users\\abhi3\\Documents\\work\\ds-algo\\pyspark_practice\\test.txt\"\n",
    "columns=[\"product_id\"  ,\"start_date\",  \"end_date\",    \"price\"  ]\n",
    "columns=[\"product_id \" ,\"purchase_date\"  ,\"units\"]\n",
    "columns=[\"account_id\",\"income\"]\n",
    "columns=[\"employee_id\",\"name\",\"manager_id\",\"salary\"]\n",
    "columns=[\"id\",  \"student\" ]\n",
    "columns=[\"movie_id\",\"user_id\",\"rating\",\"created_at\"]\n",
    "columns=[\"customer_id\",\"name\",\"visited_on\",\"amount\"]\n",
    "df=spark.read_from_text(text_path,columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b396068c-a70e-472f-9a58-dfc481c4516e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+------+\n",
      "|customer_id|   name|visited_on|amount|\n",
      "+-----------+-------+----------+------+\n",
      "|          1|   Jhon|2019-01-01|   100|\n",
      "|          2| Daniel|2019-01-02|   110|\n",
      "|          3|   Jade|2019-01-03|   120|\n",
      "|          4| Khaled|2019-01-04|   130|\n",
      "|          5|Winston|2019-01-05|   110|\n",
      "|          6|  Elvis|2019-01-06|   140|\n",
      "|          7|   Anna|2019-01-07|   150|\n",
      "|          8|  Maria|2019-01-08|    80|\n",
      "|          9|   Jaze|2019-01-09|   110|\n",
      "|          1|   Jhon|2019-01-10|   130|\n",
      "|          3|   Jade|2019-01-10|   150|\n",
      "+-----------+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df1.write.jdbc(url=spark.JDBC_URL, table=\"product\", mode=\"overwrite\", properties=spark.PROPERTIES)\n",
    "spark.write_to_db(dataframe=df,tablename=\"Customer\")\n",
    "spark.read_from_db(tablename=\"Customer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91989398-63df-4d55-b1a1-4d453a6e99f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+------+\n",
      "|customer_id|   name|visited_on|amount|\n",
      "+-----------+-------+----------+------+\n",
      "|          1|   Jhon|2019-01-01|   100|\n",
      "|          2| Daniel|2019-01-02|   110|\n",
      "|          3|   Jade|2019-01-03|   120|\n",
      "|          4| Khaled|2019-01-04|   130|\n",
      "|          5|Winston|2019-01-05|   110|\n",
      "|          6|  Elvis|2019-01-06|   140|\n",
      "|          7|   Anna|2019-01-07|   150|\n",
      "|          8|  Maria|2019-01-08|    80|\n",
      "|          9|   Jaze|2019-01-09|   110|\n",
      "|          1|   Jhon|2019-01-10|   130|\n",
      "|          3|   Jade|2019-01-10|   150|\n",
      "+-----------+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93982b78-cd5e-458c-8359-54541d0ff9ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3260245315.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[21], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    df.select(col(\"amount\")).groupby([col(`visited_on`)]).sum().collect()\u001b[0m\n\u001b[1;37m                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"amount\")).groupby([col(`visited_on`)]).sum().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0476e4f-f2ef-4a17-906e-a3619c8db5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ad1f2-17d9-4c2d-8a2f-2321e5c4ad02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8a731a-319e-4ef3-a555-b02d6859c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "quer=\"\"\"\n",
    "select * \n",
    "from df1\n",
    "\"\"\"\n",
    "sqldf(quer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f72efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheetname=\"microsoft_messages\"\n",
    "sheetname=\"robinhood_trades\"\n",
    "sheetname=\"robinhood_cities\"\n",
    "sheetname=\"amazon_reviews\"\n",
    "sheetname=\"fb_events\"\n",
    "sheetname=\"tiktok_emails\"\n",
    "sheetname=\"tiktok_texts\"\n",
    "sheetname=\"cvs_pharmacy_sales\"\n",
    "df=p.read_from_excel(sheetname)\n",
    "df#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db31567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_column=\"action_date\"\n",
    "df[date_column]=pd.to_datetime(df[date_column])\n",
    "df#.head()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(sheetname, engine,index=False,if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda8f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dab3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_sql_table(sheetname, engine, schema=None, index_col=None, coerce_float=True, parse_dates=None, columns=None, chunksize=None)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0770429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###/*\n",
    "#  * https://datalemur.com/questions/completed-trades\n",
    "#  * Assume you're given the tables containing completed trade orders and user details in a Robinhood trading system.\n",
    "\n",
    "# Write a query to retrieve the top three cities that have the highest number of completed trade \n",
    "# orders listed in descending order. \n",
    "# Output the city name and the corresponding number of completed trade orders.\n",
    "#  */\n",
    "df_robinhood_trades=p.read_from_db(\"robinhood_trades\",engine)\n",
    "df_robinhood_cities=p.read_from_db(\"robinhood_cities\",engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e540b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_robinhood_trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec4853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_robinhood_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42066b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_robinhood_trades.merge(df_robinhood_cities,how=\"left\",on=[\"user_id\"])#,lsuffix=\"_l\",rsuffix=\"_r\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd813e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result=df[df.status==\"Completed\"].groupby(\"city\").count()\n",
    "#.city\n",
    "#[\"city\"]\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c43eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e740972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon_reviews=p.read_from_db(\"amazon_reviews\",engine)\n",
    "df_amazon_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2677b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon_reviews.submit_date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdfc5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon_reviews.groupby([\"product_id\",\"submit_date\"]).mean(\"stars\").index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon_reviews.index=df_amazon_reviews[\"submit_date\"]\n",
    "df_amazon_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b399a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon_reviews_agg=df_amazon_reviews.groupby([\"product_id\",df_amazon_reviews.index.month]).mean(\"stars\").sort_values(by=[\"submit_date\",\"product_id\"],ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9a73f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon_reviews_agg_1=(df_amazon_reviews.groupby([\"product_id\",df_amazon_reviews.submit_date.dt.month])\n",
    " .mean(\"stars\")\n",
    " .sort_values(by=[\"submit_date\",\"product_id\"],ascending=False)\n",
    ")\n",
    "df_amazon_reviews_agg_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c662a74b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_amazon_reviews_agg_1.unstack()[\"review_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb475f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon_reviews_agg.index.values#.get_group(\"product-id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9923d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon_reviews_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c48fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fb_events=p.read_from_db(\"fb_events\",engine)\n",
    "df_fb_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03211645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fb_events[\"event_type_num\"]=df_fb_events[\"event_type\"].apply(lambda x: 1 if x==\"click\" else 0)\n",
    "#.groupby(\"app_id\").agg\n",
    "df_fb_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f9ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fb_events.groupby(\"app_id\",as_index=False).agg({\"event_type_num\":\"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3660d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "click_df=(df_fb_events.assign(click=(np.where(df_fb_events[\"event_type\"]==\"click\",1,0)))\n",
    "                   .groupby(\"app_id\",as_index=False).agg({\"click\":\"sum\"}))\n",
    "\n",
    "#groupby(\"app_id\",as_index=True).agg({df_fb_events[df_fb_events[\"event_type_num\"]==0]:\"count\"})\n",
    "#df_fb_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "impression_df=(df_fb_events.assign(impression=(np.where(df_fb_events[\"event_type\"]==\"impression\",1,0)))\n",
    "                   .groupby(\"app_id\",as_index=False).agg({\"impression\":\"sum\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe390dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheetname=\"tiktok_emails\"\n",
    "df_tiktok_emails=p.read_from_db(sheetname,engine)\n",
    "\n",
    "sheetname=\"tiktok_texts\"\n",
    "df_tiktok_texts=p.read_from_db(sheetname,engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d38a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titok_df=df_tiktok_emails.merge(df_tiktok_texts,how=\"left\",on=\"email_id\")\n",
    "titok_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21804e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "titok_df[\"signup_diff\"]=titok_df.action_date-titok_df.signup_date\n",
    "titok_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c41426",
   "metadata": {},
   "outputs": [],
   "source": [
    "titok_df[(titok_df.signup_diff.dt.days>=1)&(titok_df.signup_action==\"Confirmed\")]\n",
    "#.query(\"signup_diff>=0 days\").groupby(\"user_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a729e96",
   "metadata": {},
   "source": [
    "### cvs_pharmacy_sales\n",
    "Write a query to calculate the total drug sales for each manufacturer. Round the answer to the nearest million and report your results in descending order of total sales. In case of any duplicates, sort them alphabetically by the manufacturer name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheetname=\"cvs_pharmacy_sales\"\n",
    "df=p.read_from_excel(sheetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df021e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e41fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"manufacturer\",as_index=True).sum(\"total_sales\").sort_values(by=\"total_sales\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0556911b",
   "metadata": {},
   "source": [
    " ### uber_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b56f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheetname=\"uber_transactions\"\n",
    "df=p.read_from_excel(sheetname)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.convert_datetime(df,\"transaction_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8249a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\abhishek\\Documents\\coding\\ds-algo\\sql\\test.csv\",sep=\"\\t\")\n",
    "df=p.convert_datetime(df,\"activity_date\")\n",
    "#df=p.convert_datetime(df,\"transaction_date\")\n",
    "#df.drop('user_id.1',axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756c3c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.write_to_db(df,\"snapchat_activites_age\",engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa76060",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['activity_id', 'user_id', 'activity_type', 'time_spent',\n",
    "       'activity_date', 'age_bucket']]#.columns#drop(\"user_id.1\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b77100",
   "metadata": {},
   "source": [
    "### amazon_product_spend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc90961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\abhishek\\Documents\\coding\\ds-algo\\sql\\test.csv\",sep=\"\\t\")\n",
    "df=p.convert_datetime(df,\"transaction_date\")\n",
    "#df=p.convert_datetime(df,\"transaction_date\")\n",
    "#df.drop('user_id.1',axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.write_to_db(df,\"amazon_product_spend\",engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46704e06",
   "metadata": {},
   "source": [
    "# Top 5 Artists [Spotify SQL Interview Question]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874032b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\abhishek\\Documents\\coding\\ds-algo\\sql\\test.csv\",sep=\"\\t\")\n",
    "#df=p.convert_datetime(df,\"transaction_date\")\n",
    "#df=p.convert_datetime(df,\"transaction_date\")\n",
    "#df.drop('user_id.1',axis=0)\n",
    "df#=df.drop([\"artist_id.1\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a842d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ad5bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.write_to_db(df,\"spotify_artists_songs_global_song_rank\",engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bbd4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "quer=\"\"\"\n",
    "select artist_id,artist_name\n",
    "from (\n",
    "select artist_id,artist_name\n",
    ",dense_rank() over(order by count(\"song_id.1\") desc) as artist_rank\n",
    "from df\n",
    "where rank<=10\n",
    "group by artist_id,artist_name\n",
    ") cte\n",
    "where artist_rank<=5\n",
    "\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "#quer=\"select * from df where rank<10\"\n",
    "sqldf(quer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa663bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_string=\"\"\"\n",
    "\n",
    "artist_id\tartist_name\tlabel_owner\tsong_id\tartist_id\tname\tday\tsong_id\trank\n",
    "101\tEd Sheeran\tWarner Music Group\t45202\t101\tShape of You\t1\t45202\t2\n",
    "101\tEd Sheeran\tWarner Music Group\t45202\t101\tShape of You\t3\t45202\t2\n",
    "101\tEd Sheeran\tWarner Music Group\t45202\t101\tShape of You\t15\t45202\t6\n",
    "101\tEd Sheeran\tWarner Music Group\t55511\t101\tPerfect\t2\t55511\t2\n",
    "120\tDrake\tWarner Music Group\t19960\t120\tHotline Bling\t1\t19960\t3\n",
    "120\tDrake\tWarner Music Group\t19960\t120\tHotline Bling\t9\t19960\t15\n",
    "125\tBad Bunny\tRimas Entertainment\t12636\t125\tMia\t23\t12636\t9\n",
    "125\tBad Bunny\tRimas Entertainment\t12636\t125\tMia\t24\t12636\t7\n",
    "125\tBad Bunny\tRimas Entertainment\t12636\t125\tMia\t2\t12636\t23\n",
    "125\tBad Bunny\tRimas Entertainment\t12636\t125\tMia\t29\t12636\t7\n",
    "125\tBad Bunny\tRimas Entertainment\t69820\t125\tDakiti\t1\t69820\t1\n",
    "125\tBad Bunny\tRimas Entertainment\t44552\t125\tCallaita\t17\t44552\t8\n",
    "125\tBad Bunny\tRimas Entertainment\t44552\t125\tCallaita\t11\t44552\t16\n",
    "145\tLady Gaga\tInterscope Records\t11254\t145\tBad Romance\t11\t11254\t5\n",
    "145\tLady Gaga\tInterscope Records\t11254\t145\tBad Romance\t12\t11254\t16\n",
    "160\tChris Brown\tRCA Records\t33101\t160\tGo Crazy\t3\t33101\t16\n",
    "200\tAdele\tColumbia Records\t23299\t200\tHello\t6\t23299\t1\n",
    "240\tKaty Perry\tCapitol Records\t89633\t240\tLast Friday Night\t14\t89633\t2\n",
    "200\tAdele\tColumbia Records\t28079\t200\tSomeone Like You\t9\t28079\t9\n",
    "200\tAdele\tColumbia Records\t28079\t200\tSomeone Like You\t7\t28079\t10\n",
    "145\tLady Gaga\tInterscope Records\t11254\t145\tBad Romance\t40\t11254\t1\n",
    "200\tAdele\tColumbia Records\t23299\t200\tHello\t37\t23299\t5\n",
    "145\tLady Gaga\tInterscope Records\t11254\t145\tBad Romance\t19\t11254\t10\n",
    "240\tKaty Perry\tCapitol Records\t89633\t240\tLast Friday Night\t23\t89633\t10\n",
    "160\tChris Brown\tRCA Records\t33101\t160\tGo Crazy\t52\t33101\t7\n",
    "101\tEd Sheeran\tWarner Music Group\t55511\t101\tPerfect\t20\t55511\t10\n",
    "120\tDrake\tWarner Music Group\t22222\t120\tOne Dance\t7\t22222\t8\n",
    "125\tBad Bunny\tRimas Entertainment\t44552\t125\tCallaita\t8\t44552\t1\n",
    "260\tTaylor Swift\tUniversal Music Group\t54622\t260\tWildest Dreams\t1\t54622\t34\n",
    "125\tBad Bunny\tRimas Entertainment\t44552\t125\tCallaita\t2\t44552\t1\n",
    "120\tDrake\tWarner Music Group\t19960\t120\tHotline Bling\t2\t19960\t3\n",
    "120\tDrake\tWarner Music Group\t22222\t120\tOne Dance\t3\t22222\t35\n",
    "270\tAriana Grande\tUniversal Music Group\t56112\t270\t7 Rings\t3\t56112\t3\n",
    "260\tTaylor Swift\tUniversal Music Group\t14525\t260\tCruel Summer\t4\t14525\t1\n",
    "250\tThe Weeknd\tUniversal Music Group\t23339\t250\tBlinding Lights\t4\t23339\t29\n",
    "120\tDrake\tWarner Music Group\t13997\t120\tRich Flex\t4\t13997\t5\n",
    "260\tTaylor Swift\tUniversal Music Group\t87752\t260\tKarma\t13\t87752\t1\n",
    "260\tTaylor Swift\tUniversal Music Group\t87752\t260\tKarma\t14\t87752\t1\n",
    "145\tLady Gaga\tInterscope Records\t11254\t145\tBad Romance\t1\t11254\t12\n",
    "120\tDrake\tWarner Music Group\t13997\t120\tRich Flex\t51\t13997\t1\n",
    "200\tAdele\tColumbia Records\t28079\t200\tSomeone Like You\t52\t28079\t75\n",
    "260\tTaylor Swift\tUniversal Music Group\t87752\t260\tKarma\t15\t87752\t1\n",
    "260\tTaylor Swift\tUniversal Music Group\t14525\t260\tCruel Summer\t5\t14525\t1\n",
    "260\tTaylor Swift\tUniversal Music Group\t14525\t260\tCruel Summer\t6\t14525\t2\n",
    "260\tTaylor Swift\tUniversal Music Group\t14525\t260\tCruel Summer\t7\t14525\t1\n",
    "160\tChris Brown\tRCA Records\t33101\t160\tGo Crazy\t40\t33101\t13\n",
    "260\tTaylor Swift\tUniversal Music Group\t54622\t260\tWildest Dreams\t1\t54622\t84\n",
    "260\tTaylor Swift\tUniversal Music Group\t62887\t260\tAnti-Hero\t7\t62887\t2\n",
    "240\tKaty Perry\tCapitol Records\t89633\t240\tLast Friday Night\t50\t89633\t67\n",
    "120\tDrake\tWarner Music Group\t13997\t120\tRich Flex\t50\t13997\t1\n",
    "120\tDrake\tWarner Music Group\t13997\t120\tRich Flex\t33\t13997\t3\n",
    "200\tAdele\tColumbia Records\t23299\t200\tHello\t1\t23299\t9\n",
    "270\tAriana Grande\tUniversal Music Group\t86645\t270\tThank U, Next\tNULL\tNULL\tNULL\n",
    "260\tTaylor Swift\tUniversal Music Group\t23689\t260\tBlank Space\tNULL\tNULL\tNULL\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ff812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p.read_csv_var(csv_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561194c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customer_contracts=\"\"\"\n",
    "customer_id\tproduct_id\tamount\n",
    "1\t1\t1000\n",
    "2\t2\t2000\n",
    "3\t1\t1100\n",
    "4\t1\t1000\n",
    "7\t1\t1000\n",
    "7\t3\t4000\n",
    "6\t4\t2000\n",
    "1\t5\t1500\n",
    "2\t5\t2000\n",
    "4\t5\t2200\n",
    "7\t6\t5000\n",
    "1\t2\t2000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06579f62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_customer_contracts=p.read_csv_var(customer_contracts)\n",
    "df_customer_contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c811c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "products=\"\"\"\n",
    "product_id\tproduct_category\tproduct_name\n",
    "1\tAnalytics\tAzure Databricks\n",
    "2\tAnalytics\tAzure Stream Analytics\n",
    "3\tContainers\tAzure Kubernetes Service\n",
    "4\tContainers\tAzure Service Fabric\n",
    "5\tCompute\tVirtual Machines\n",
    "6\tCompute\tAzure Functions\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea79395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products=p.read_csv_var(products)\n",
    "df_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60c14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "select * from df_customer_contracts cc left join df_products p on cc.product_id=p.product_id\n",
    "\"\"\"\n",
    "df_join=sqldf(query)\n",
    "df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query=\"\"\"\n",
    "# select customer_id,product_name \n",
    "# from df_customer_contracts cc left join df_products p on cc.product_id=p.product_id\n",
    "\n",
    "# group by customer_id\n",
    "# order by customer_id\n",
    "# \"\"\"\n",
    "# sqldf(query)\n",
    "df_join.groupby(\"customer_id\").count()\n",
    "#len(df_join[\"product_category\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470174e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#having count(cc.product_id)=(select count(distinct p.product_name) from df_products )\n",
    "query=\"\"\"\n",
    "select customer_id,count(product_category) as product_category_count\n",
    "--,(select count(distinct(product_category)) from df_products)\n",
    "from df_customer_contracts cc left join df_products p on cc.product_id=p.product_id\n",
    "where 1=1\n",
    "and product_category = 'Analytics'\n",
    "and product_category = 'Containers'\n",
    "and product_category ='Compute'\n",
    "group by customer_id\n",
    "--,product_category\n",
    "\n",
    "--having count(product_name)=3\n",
    "--(select count(distinct(product_category)) from df_products)\n",
    "order by customer_id\n",
    "\"\"\"\n",
    "sqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b290cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#having count(cc.product_id)=(select count(distinct p.product_name) from df_products )\n",
    "query=\"\"\"\n",
    "select customer_id,\n",
    "sum(\n",
    "case when product_category in ('Analytics','Containers','Compute') then 1 else 0\n",
    "end\n",
    ") as count_pc\n",
    "from df_customer_contracts cc left join df_products p on cc.product_id=p.product_id\n",
    "and product_category in ('Analytics','Containers','Compute')\n",
    "group by customer_id\n",
    "--,product_category\n",
    "\n",
    "--having count(product_name)=3\n",
    "--(select count(distinct(product_category)) from df_products)\n",
    "order by customer_id\n",
    "\"\"\"\n",
    "sqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd32c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "with cte as (\n",
    "select * \n",
    "from df_customer_contracts cc left join df_products p on cc.product_id=p.product_id\n",
    ")\n",
    "select * from cte\n",
    "--group by customer_id\n",
    "order by customer_id asc \n",
    "\"\"\"\n",
    "sqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c22077",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "with cte as (\n",
    "select * ,dense_rank() over(partition by customer_id order by product_category) as product_rank\n",
    "from df_customer_contracts cc left join df_products p on cc.product_id=p.product_id\n",
    ")\n",
    "select customer_id\n",
    "from cte\n",
    "group by customer_id\n",
    "having product_rank=(select count(distinct product_category) from df_products)\n",
    "\"\"\"\n",
    "sqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df818b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "with cte as (\n",
    "select * ,dense_rank() over(partition by customer_id order by product_category) as product_rank\n",
    "from df_customer_contracts cc left join df_products p on cc.product_id=p.product_id\n",
    ")\n",
    "select customer_id\n",
    "from cte\n",
    "where product_rank=(select count(distinct product_category) from df_products)\n",
    "group by customer_id\n",
    "\n",
    "--\n",
    "\"\"\"\n",
    "sqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945902d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "with cte as (\n",
    "select customer_id\n",
    ",count(distinct p.product_category) as dist_count_product_category\n",
    "from df_customer_contracts cc left join df_products p on cc.product_id=p.product_id\n",
    "group by customer_id\n",
    ")\n",
    "select customer_id\n",
    "\n",
    "from cte\n",
    "where dist_count_product_category= (select count(distinct product_category) from df_products )\n",
    "\n",
    "\"\"\"\n",
    "sqldf(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a53d26",
   "metadata": {},
   "source": [
    "# Google https://datalemur.com/questions/odd-even-measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1892411",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements=\"\"\"\n",
    "measurement_id\tmeasurement_value\tmeasurement_time\tday\n",
    "131233\t1109.51\t07/10/2022 09:00:00\tNULL\n",
    "135211\t1662.74\t07/10/2022 11:00:00\tNULL\n",
    "143562\t1124.50\t07/11/2022 13:15:00\tNULL\n",
    "346462\t1234.14\t07/11/2022 15:00:00\tNULL\n",
    "124245\t1252.62\t07/11/2022 16:45:00\tNULL\n",
    "523542\t1246.24\t07/10/2022 14:30:00\tNULL\n",
    "143251\t1246.56\t07/11/2022 18:00:00\tNULL\n",
    "141565\t1452.40\t07/12/2022 08:00:00\tNULL\n",
    "253622\t1244.30\t07/12/2022 14:00:00\tNULL\n",
    "353625\t1451.00\t07/12/2022 15:00:00\tNULL\n",
    "\"\"\"\n",
    "\n",
    "df_measurements=p.read_csv_var(measurements)\n",
    "df_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c212581",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_measurements=p.read_csv_var(measurements)\n",
    "df_measurements\n",
    "df_measurements=p.convert_datetime(df_measurements,\"measurement_time\")\n",
    "df_measurements\n",
    "p.write_to_db(df_measurements,\"google_odd_even_measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc8902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "with cte as (\n",
    "select \n",
    "*\n",
    ", row_number() over(partition by cast(measurement_time as date) order by measurement_time asc) as measurement_num\n",
    "from df_measurements\n",
    ")\n",
    "select cast(measurement_time as date)\n",
    ",sum(case when measurement_num%2!=0 then measurement_value end) as odd_sum\n",
    ",sum(case when measurement_num%2=0 then measurement_value end) as even_sum\n",
    "from cte\n",
    "group by cast(measurement_time as date)\n",
    "\n",
    ";\n",
    "\n",
    "\"\"\"\n",
    "#sqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a1f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_measurements.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e4f242",
   "metadata": {},
   "source": [
    "# Walmart https://datalemur.com/questions/histogram-users-purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aae2473",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_transactions=\"\"\"\n",
    "product_id\tuser_id\tspend\ttransaction_date\n",
    "3673\t123\t68.90\t07/08/2022 10:00:00\n",
    "9623\t123\t274.10\t07/08/2022 10:00:00\n",
    "1467\t115\t19.90\t07/08/2022 10:00:00\n",
    "2513\t159\t25.00\t07/08/2022 10:00:00\n",
    "1452\t159\t74.50\t07/10/2022 10:00:00\n",
    "1452\t123\t74.50\t07/10/2022 10:00:00\n",
    "9765\t123\t100.15\t07/11/2022 10:00:00\n",
    "6536\t115\t57.00\t07/12/2022 10:00:00\n",
    "7384\t159\t15.50\t07/12/2022 10:00:00\n",
    "1247\t159\t23.40\t07/12/2022 10:00:00\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_transactions=p.read_csv_var(user_transactions)\n",
    "df_user_transactions=p.convert_datetime(df_user_transactions,\"transaction_date\")\n",
    "\n",
    "p.write_to_db(df_user_transactions,\"walmart_df_user_transactions\")\n",
    "df_user_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1887719",
   "metadata": {},
   "outputs": [],
   "source": [
    "quer=\"\"\"\n",
    "select transaction_date,user_id,count(spend) as purchase_count \n",
    "from (\n",
    "SELECT transaction_date,user_id,spend\n",
    ", dense_rank() over(partition by user_id order by transaction_date desc) spend_rank\n",
    "FROM df_user_transactions\n",
    ") as cte\n",
    "where spend_rank=1\n",
    "group by transaction_date,user_id\n",
    "\n",
    "\"\"\"\n",
    "sqldf(quer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252e2714",
   "metadata": {},
   "source": [
    "# Verizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2e0ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_info_phone_calls=\"\"\"\n",
    "caller_id\treceiver_id\tcall_time\tcaller_id\tcountry_id\tnetwork\tphone_number\treceiver_id\n",
    "7\t4\t09/03/2022 00:04:30\t7\tUS\tVerizon\t+1-415-224-6663\tNULL\n",
    "11\t31\t07/11/2022 04:18:03\t11\tIN\tVodafone\t+91 7503-907302\tNULL\n",
    "12\t50\t08/04/2022 02:01:16\t12\tIN\tVodafone\t+91 2287-664895\tNULL\n",
    "13\t6\t07/16/2022 01:45:59\t13\tUK\tVodafone\t+44 7700 900442\tNULL\n",
    "24\t36\t07/31/2022 07:16:09\t24\tDE\tDeutsche Telekom\t+49 30 901820\tNULL\n",
    "14\t31\t10/29/2022 00:44:04\t14\tUK\tVodafone\t+44 117 496 0108\tNULL\n",
    "35\t36\t11/01/2022 11:00:00\t35\tDE\tDeutsche Telekom\t+49 30 221447813\tNULL\n",
    "37\t46\t09/01/2022 09:50:24\t37\tDE\tDeutsche Telekom\t+49 30 578535325\tNULL\n",
    "45\t35\t06/14/2022 00:42:39\t45\tDE\tDeutsche Telekom\t+49 30 725036951\tNULL\n",
    "5\t34\t08/07/2022 18:50:13\t5\tUS\tVerizon\t+1-212-346-9529\tNULL\n",
    "5\t33\t05/14/2022 19:33:04\t5\tUS\tVerizon\t+1-212-346-9529\tNULL\n",
    "\"\"\"\n",
    "phone_info_phone_calls_df=p.read_csv_var(phone_info_phone_calls)\n",
    "phone_info_phone_calls_df\n",
    "#p.write_to_db(phone_info_phone_calls_df,\"verizon_phone_info_phone_calls\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1=\"\"\"\n",
    "\n",
    "select (select  count(distinct caller_id) from phone_info_phone_calls_df where caller_id<receiver_id)\n",
    "/(select count(*) from phone_info_phone_calls_df)::decimal\n",
    "from phone_info_phone_calls_df\n",
    "--where  caller_id<receiver_id\n",
    "group by caller_id\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "sqldf(query1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25b7adc",
   "metadata": {},
   "source": [
    "# Wayfair year on year\n",
    "https://datalemur.com/questions/yoy-growth-rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a3178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=r\"C:\\Users\\abhishek\\Documents\\coding\\ds-algo\\sql\\test.csv\"\n",
    "user_transactions =pd.read_csv(filepath,sep=\"\\t\")\n",
    "user_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.write_to_db(user_transactions,\"wayfair_user_transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18709ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_transactions[\"transaction_date\"]=pd.to_datetime(user_transactions[\"transaction_date\"])\n",
    "p.write_to_db(user_transactions,\"wayfair_user_transactions\")\n",
    "# user_transactions[\"revenue_year\"]=user_transactions.transaction_date.dt.year\n",
    "# user_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a67902",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "select *,\n",
    "100* ((curr_year_spend-prev_year_spend)/curr_year_spend) as yoy_rate\n",
    "\n",
    "from (\n",
    "\n",
    "select * \n",
    ",lag(curr_year_spend,1) over(partition by product_id order by product_id,revenue_year asc) as prev_year_spend\n",
    "from (\n",
    "\n",
    "select * \n",
    ",sum(spend) as curr_year_spend\n",
    "from user_transactions\n",
    "group by product_id,revenue_year\n",
    ") as cte\n",
    "--order by product_id,revenue_year desc\n",
    ") as cte1\n",
    "\"\"\"\n",
    "sqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24942156",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "select *,\n",
    "100* ((curr_year_spend-prev_year_spend)/curr_year_spend) as yoy_rate\n",
    "\n",
    "from (\n",
    "\n",
    "select * \n",
    ",lag(curr_year_spend,1) over(partition by product_id order by product_id,year asc) as prev_year_spend\n",
    "from (\n",
    "\n",
    "select * ,revenue_year as year\n",
    ",sum(spend) as curr_year_spend\n",
    "from user_transactions\n",
    "group by product_id,revenue_year\n",
    ") as cte\n",
    "--order by product_id,revenue_year desc\n",
    ") as cte1\n",
    "\"\"\"\n",
    "sqldf(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a0f50a",
   "metadata": {},
   "source": [
    "##  Facebook\n",
    "https://datalemur.com/questions/user-retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bb4ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_inventory =p.read_from_csv()\n",
    "#user_actions=p.convert_datetime(amazon_inventory,\"event_date\")\n",
    "amazon_inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbe8890",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.write_to_db(amazon_inventory,\"amazon_inventory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d508d47",
   "metadata": {},
   "source": [
    "# Google\n",
    "https://datalemur.com/questions/median-search-freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f9dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_frequency =p.read_from_csv()\n",
    "p.write_to_db(search_frequency,\"google_search_frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e6fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "\n",
    "SELECT * FROM generate_series(0,10000000);\n",
    "\n",
    "\"\"\"\n",
    "sqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a11358",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree =p.read_from_csv()\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901487e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b1ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query=\"\"\"\n",
    "\n",
    "with leaf as (\n",
    "select id,\n",
    "case \n",
    "--when parent_id not in (select distinct id from tree) then 'parent'\n",
    "--when parent_id in (select distinct id from tree) then 'child'\n",
    "when id not in (select distinct parent_id from tree) then 'leaf'\n",
    "else null\n",
    "end as type\n",
    "from tree t1\n",
    "where 1=1\n",
    "and type!='None'\n",
    "),\n",
    "subtree as (\n",
    "select parent_id,id,\n",
    "case \n",
    "when parent_id not in (select distinct id from tree) then 'parent'\n",
    "when parent_id in (select distinct id from tree) then 'child'\n",
    "--when id not in (select distinct parent_id from tree) then 'leaf'\n",
    "else null\n",
    "end as type\n",
    "from tree t1\n",
    "where 1=1\n",
    ")\n",
    ",\n",
    "tree_node as (\n",
    "select distinct parent_id as p_id  from tree \n",
    "union \n",
    "select distinct id as p_id from tree\n",
    "order by p_id\n",
    ")\n",
    "\n",
    "select *\n",
    "from tree_node tn left join subtree s on\n",
    "tn.p_id=s.parent_id \n",
    "left join leaf l on \n",
    "tn.p_id=l.id \n",
    "\n",
    "group by p_id\n",
    "\"\"\"\n",
    "\n",
    "sqldf(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d707f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_csv_str=\"\"\"\n",
    "id \t p_id\n",
    "1\t null \n",
    "2\t1\n",
    "3\t1\n",
    "4\t2\n",
    "5\t2\n",
    "\"\"\"\n",
    "query=\"\"\"\n",
    "\n",
    "select id\n",
    "\n",
    "case when p_id=null then 'parent'\n",
    "when p_id in (select id from tree) then 'child'\n",
    "when id not in (select p_id from tree) then 'leaf'\n",
    "end as type\n",
    "from tree\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#tree=p.read_csv_var(csv_str)\n",
    "\n",
    "#tree\n",
    "sqldf(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdfa820",
   "metadata": {},
   "source": [
    "# read from database and get partition number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061a11a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
